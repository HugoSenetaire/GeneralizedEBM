fid_b_size: 100
b_size : 2000
dataset: imagenet32

total_epochs: 10

g_model : 'sngan'
d_model : 'sngan'

optimizer: Adam

criterion : 'kale'

# load pretrained weights
# use a single generator for all tests
#d_path : '/nfs/gatsbystor/michaela/projects/kale/exp/rebuttal/sngan_imagenet/train/checkpoints_7154343/d_66007.pth'
#g_path : '/nfs/gatsbystor/michaela/projects/kale/exp/rebuttal/sngan_imagenet/train/checkpoints_7154343/g_66007.pth'


#d_path : '/nfs/gatsbystor/michaela/projects/kale/exp/rebuttal/sngan_imagenet/train/checkpoints_7154343/d_126067.pth'
g_path : '/nfs/gatsbystor/michaela/projects/kale/exp/rebuttal/sngan_imagenet/train/checkpoints_7154343/g_126067.pth'

d_path : '/nfs/gatsbystor/michaela/projects/kale/exp/rebuttal/sampling_imagenet_4/tune_and_fids/checkpoints_1957156/d_best.pth'


imagenet_train_path: /nfs/gatsbystor/michaela/imagenet/imagenet32/out_data_train/
imagenet_test_path: /nfs/gatsbystor/michaela/imagenet/imagenet32/out_data_val/

data_path : '/nfs/gatsbystor/michaela/projects/data/'
log_dir : '/nfs/gatsbystor/michaela/projects/kale/exp/neurips'
log_name : 'sampling_imagenet_5'

penalty_type : 'gradient'
penalty_lambda : 1.

scheduler : 'ExponentialLR'
scheduler_gamma : 0.8
beta_1 : 0.5
beta_2 : 0.999

lr : 0.00001

with_fid : True

# train
mode : sample
fid_samples : 50000

# sampling stuff
Z_dim : 100
sample_b_size : 2000

log_to_file : True


lmc_gamma : .0001
lmc_kappa : .04
#latent_sampler : 'langevin'
num_lmc_steps : 1000
seed : 0
eval_fid : True
#temperature : 100.
