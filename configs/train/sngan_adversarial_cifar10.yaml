b_size: 128
dataset: cifar10
total_gen_iter: 150000

g_model : 'sngan'
d_model : 'sngan'

optimizer: Adam
criterion : 'donsker'
log_dir : '/nfs/gatsbystor/michaela/projects/kale/exp/neurips'
log_name : 'dcgan_kale_cifar10'

penalty_type : 'gradient'
penalty_lambda : 1.

scheduler : 'ExponentialLR'
scheduler_gamma : 0.8
beta_1 : 0.5
beta_2 : 0.999

# train
#mode : train
train_mode : 'both'
with_fid : True

#use_scheduler : True

# sampling stuff
Z_dim : 100
sample_b_size : 128



seed : 0
fid_samples : 50000

#latent_sampler : 'hmc'
bn : False
skipinit : False


lr : 0.0001
lr_generator : 0.0001

eval_fid : True
eval_kale : True

# disp_freq : 10
# checkpoint_freq : 10

# n_iter_d_init : 1
# n_iter_d : 1

# fid_samples : 500

# freq_fid : 10
# freq_kale : 10

log_to_file : True
mode : 'train'

